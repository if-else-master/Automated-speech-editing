import cv2
import easyocr
import numpy as np
import imagehash
from PIL import Image, ImageDraw, ImageFont
import requests 
import re
import os
import threading
import tkinter as tk
from tkinter import filedialog, messagebox
from tkinter import ttk  # æ–°å¢ï¼Œç”¨æ–¼æ¨™ç±¤é 

def lock_api():
    global GEMINI_API_KEY
    GEMINI_API_KEY = api_key_entry.get()
    print("ğŸ”‘ é–å®šé‡‘é‘°:", GEMINI_API_KEY)
    
GEMINI_API_KEY = ""

def extract_slides(video_path, output_dir, frame_interval, hash_diff_threshold, status_label, counter_label):
    os.makedirs(output_dir, exist_ok=True)
    cap = cv2.VideoCapture(video_path)

    frame_count = 0
    prev_hash = None
    slide_index = 0
    output_img = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        if frame_count % frame_interval == 0:
            pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            curr_hash = imagehash.phash(pil_image)

            if prev_hash is None or abs(curr_hash - prev_hash) > hash_diff_threshold:
                filename = os.path.join(output_dir, f'slide_{slide_index:02d}.jpg')
                pil_image.save(filename)
                process_image(filename,f'ocr_output/out_{output_img:02d}.jpg')
                slide_index += 1
                output_img += 1
                prev_hash = curr_hash
                counter_label.config(text=f"å·²æ“·å–é æ•¸ï¼š{slide_index}")

        frame_count += 1

    cap.release()
    status_label.config(text="ğŸ‰ æ“·å–å®Œæˆï¼")
    messagebox.showinfo("å®Œæˆ", f"æˆåŠŸæ“·å– {slide_index} å¼µæŠ•å½±ç‰‡ï¼")

def browse_file(entry):
    path = filedialog.askopenfilename(filetypes=[("MP4 files", "*.mp4")])
    if path:
        entry.delete(0, tk.END)
        entry.insert(0, path)

def start_process(video_entry, interval_entry, threshold_entry, status_label, counter_label):
    video_path = video_entry.get()
    if not os.path.isfile(video_path):
        messagebox.showerror("éŒ¯èª¤", "å½±ç‰‡è·¯å¾‘éŒ¯èª¤æˆ–ä¸å­˜åœ¨ï¼")
        return

    try:
        interval = int(interval_entry.get())
        threshold = int(threshold_entry.get())
    except ValueError:
        messagebox.showerror("éŒ¯èª¤", "è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—åƒæ•¸")
        return

    status_label.config(text="ğŸš€ æ­£åœ¨æ“·å–ä¸­...")
    counter_label.config(text="")

    output_dir = "slides_output"
    threading.Thread(target=extract_slides, args=(video_path, output_dir, interval, threshold, status_label, counter_label)).start()
    
    
## OCR##############################
def translate_with_gemini(text, api_key, target_lang="Japanese"):
    """
    å°‡è¼¸å…¥çš„ç¹é«”ä¸­æ–‡ text ç¿»è­¯æˆ target_langï¼ˆé è¨­ Japaneseï¼‰ï¼Œ
    åƒ…å›å‚³ç¿»è­¯å¾Œçš„ç´”æ–‡å­—ï¼Œä¸åŒ…å«ä»»ä½•é¡å¤–å…§å®¹ã€‚
    """
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}"
    headers = {"Content-Type": "application/json"}
    prompt = f"è«‹å°‡ä»¥ä¸‹ç¹é«”ä¸­æ–‡ç¿»è­¯æˆ{target_lang}ï¼Œåªè¼¸å‡ºç¿»è­¯çµæœï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡‹æˆ–é¡å¤–æ–‡å­—ï¼š{text}"
    payload = {
        "contents": [{"parts": [{"text": prompt}]}]
    }
    r = requests.post(url, headers=headers, json=payload)
    if r.status_code == 200:
        try:
            translated = r.json()["candidates"][0]["content"]["parts"][0]["text"]
            # å»é™¤æ‰€æœ‰å¯èƒ½çš„å‰å°æ–‡å­—ï¼Œåªä¿ç•™å¯¦éš›ç¿»è­¯
            clean_result = re.sub(r'^[^a-zA-Z\u3040-\u30FF\u3400-\u4DBF\u4E00-\u9FFF]+', '', translated).strip()
            return clean_result
        except (KeyError, IndexError):
            return text
    else:
        print("âš ï¸ ç¿»è­¯å¤±æ•—:", r.text)
        return text

def remove_text_with_inpainting(img, boxes):
    """
    æ ¹æ“š OCR å›å‚³çš„ boxes å››é»åº§æ¨™ï¼Œè£½ä½œ mask ä¸¦ inpaintã€‚
    """
    mask = np.zeros(img.shape[:2], dtype=np.uint8)
    for box in boxes:
        pts = np.array(box, dtype=np.int32)
        cv2.fillPoly(mask, [pts], 255)
    return cv2.inpaint(img, mask, 3, cv2.INPAINT_TELEA)

def draw_translated_text(pil_img, boxes, texts, font_path):
    """
    åœ¨ PIL Image ä¸Šï¼Œä¾ç…§åŸæœ¬ boxes çš„ä½ç½®è²¼å›ç¿»è­¯å¾Œçš„æ–‡æœ¬ï¼Œ
    å‹•æ…‹è¨ˆç®—å­—å‹å¤§å°ã€æ›è¡Œï¼Œç¢ºä¿æ–‡å­—ç½®å…¥æ¡†å…§ã€‚
    """
    draw = ImageDraw.Draw(pil_img)
    for box, txt in zip(boxes, texts):
        xs = [p[0] for p in box]
        ys = [p[1] for p in box]
        x0, y0 = min(xs), min(ys)
        x1, y1 = max(xs), max(ys)
        box_w, box_h = x1 - x0, y1 - y0

        font_size = max(int(box_h * 0.8), 12)
        font = ImageFont.truetype(font_path, font_size)

        max_chars = max(int(box_w / (font_size * 0.6)), 1)
        lines = [txt[i:i+max_chars] for i in range(0, len(txt), max_chars)]

        y = y0
        for line in lines:
            draw.text((x0, y), line, font=font, fill=(0, 0, 0))
            y += font_size
    return pil_img

def process_image(image_path, output_path):
    # è®€å–åœ–ç‰‡
    img = cv2.imread(image_path)
    # OCR åƒ…åµæ¸¬ç¹é«”ä¸­æ–‡
    reader = easyocr.Reader(['ch_tra'], gpu=False)
    results = reader.readtext(img)

    boxes, orig_texts = [], []
    for box, text, conf in results:
        if conf > 0.4:
            boxes.append(box)
            orig_texts.append(text)

    # ç§»é™¤åŸæ–‡æ–‡å­—
    img_clean = remove_text_with_inpainting(img, boxes)

    # ç¿»è­¯æ‰€æœ‰æ–‡å­—
    translated = [translate_with_gemini(t, GEMINI_API_KEY, target_lang="Japanese") for t in orig_texts]

    # è½‰ç‚º PIL é€²è¡Œè²¼å­—
    pil_img = Image.fromarray(cv2.cvtColor(img_clean, cv2.COLOR_BGR2RGB))
    # æ—¥æ–‡å­—å‹
    font_jp = "NotoSansCJKjp-Regular.otf"

    final = draw_translated_text(pil_img, boxes, translated, font_jp)
    final.save(output_path)
    print(f"âœ… è¼¸å‡ºå®Œæˆï¼š{output_path}")


## æ–°å¢åŠŸèƒ½ï¼šå°‡ç¿»è­¯å¥½çš„æŠ•å½±ç‰‡åˆæˆç‚ºå½±ç‰‡ ##############
def create_translated_video(video_path, translated_slides_dir, output_video_path, frame_interval, hash_diff_threshold, status_label, progress_label):
    """
    å°‡ç¿»è­¯å¥½çš„æŠ•å½±ç‰‡åœ–ç‰‡åˆæˆåˆ°åŸå§‹å½±ç‰‡ä¸­
    
    åƒæ•¸:
        video_path: åŸå§‹å½±ç‰‡è·¯å¾‘
        translated_slides_dir: ç¿»è­¯å¾ŒæŠ•å½±ç‰‡çš„ç›®éŒ„
        output_video_path: è¼¸å‡ºå½±ç‰‡è·¯å¾‘
        frame_interval: æª¢æŸ¥å½±æ ¼çš„é–“éš”
        hash_diff_threshold: åˆ¤æ–·å¹€è®ŠåŒ–çš„é–¾å€¼
        status_label: ç‹€æ…‹æ¨™ç±¤
        progress_label: é€²åº¦æ¨™ç±¤
    """
    # å‰µå»ºè¼¸å‡ºç›®éŒ„ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    output_dir = os.path.dirname(output_video_path)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir, exist_ok=True)
        
    # è®€å–æ‰€æœ‰ç¿»è­¯å¥½çš„æŠ•å½±ç‰‡
    translated_slides = {}
    for filename in os.listdir(translated_slides_dir):
        if filename.startswith('out_') and filename.endswith('.jpg'):
            slide_index = int(filename.split('_')[1].split('.')[0])
            slide_path = os.path.join(translated_slides_dir, filename)
            translated_slides[slide_index] = slide_path
    
    if not translated_slides:
        messagebox.showerror("éŒ¯èª¤", "æ‰¾ä¸åˆ°ç¿»è­¯å¾Œçš„æŠ•å½±ç‰‡ï¼")
        status_label.config(text="âŒ æ‰¾ä¸åˆ°ç¿»è­¯å¾Œçš„æŠ•å½±ç‰‡")
        return
    
    # æ‰“é–‹åŸå§‹å½±ç‰‡
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        messagebox.showerror("éŒ¯èª¤", "ç„¡æ³•é–‹å•Ÿå½±ç‰‡æª”æ¡ˆï¼")
        status_label.config(text="âŒ ç„¡æ³•é–‹å•Ÿå½±ç‰‡æª”æ¡ˆ")
        return
    
    # å–å¾—å½±ç‰‡åƒæ•¸
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # è¨­å®šè¼¸å‡ºå½±ç‰‡ç·¨ç¢¼å™¨
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))
    
    # åˆå§‹åŒ–å¹€è¨ˆæ•¸å’Œé›œæ¹Šå€¼
    frame_count = 0
    prev_hash = None
    current_slide_index = 0
    current_slide = None
    
    # æ›´æ–°é€²åº¦æ¨™ç±¤
    progress_label.config(text=f"é€²åº¦: 0/{total_frames} å¹€")
    
    # è™•ç†æ¯ä¸€å¹€
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æŠ•å½±ç‰‡
        if frame_count % frame_interval == 0:
            # è¨ˆç®—ç›®å‰å¹€çš„å“ˆå¸Œå€¼
            pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            curr_hash = imagehash.phash(pil_image)
            
            # å¦‚æœå“ˆå¸Œå€¼èˆ‡å‰ä¸€å¹€å·®ç•°è¼ƒå¤§ï¼Œå‰‡åˆ¤å®šç‚ºæ–°æŠ•å½±ç‰‡
            if prev_hash is None or abs(curr_hash - prev_hash) > hash_diff_threshold:
                if current_slide_index in translated_slides:
                    # è®€å–å°æ‡‰çš„ç¿»è­¯æŠ•å½±ç‰‡
                    slide_path = translated_slides[current_slide_index]
                    current_slide = cv2.imread(slide_path)
                    # ç¢ºä¿å°ºå¯¸èˆ‡å½±ç‰‡ä¸€è‡´
                    if current_slide.shape[0] != height or current_slide.shape[1] != width:
                        current_slide = cv2.resize(current_slide, (width, height))
                
                current_slide_index += 1
                prev_hash = curr_hash
        
        # å¦‚æœæœ‰å°æ‡‰çš„ç¿»è­¯æŠ•å½±ç‰‡ï¼Œå‰‡æ›¿æ›ç•¶å‰å¹€
        if current_slide is not None:
            output_frame = current_slide.copy()
        else:
            output_frame = frame.copy()
        
        # å¯«å…¥è¼¸å‡ºå½±ç‰‡
        out.write(output_frame)
        
        # æ›´æ–°é€²åº¦
        if frame_count % 30 == 0:  # æ¯30å¹€æ›´æ–°ä¸€æ¬¡é€²åº¦ï¼Œä»¥å…UIæ›´æ–°éæ–¼é »ç¹
            progress = int((frame_count / total_frames) * 100)
            progress_label.config(text=f"é€²åº¦: {frame_count}/{total_frames} å¹€ ({progress}%)")
        
        frame_count += 1
    
    # é‡‹æ”¾è³‡æº
    cap.release()
    out.release()
    
    # æ›´æ–°å®Œæˆç‹€æ…‹
    status_label.config(text="âœ… å½±ç‰‡åˆæˆå®Œæˆï¼")
    progress_label.config(text=f"å®Œæˆè™•ç† {frame_count} å¹€")
    messagebox.showinfo("å®Œæˆ", f"æˆåŠŸå°‡ç¿»è­¯æŠ•å½±ç‰‡åˆæˆåˆ°å½±ç‰‡ä¸­ï¼\nè¼¸å‡ºè·¯å¾‘: {output_video_path}")

def browse_video_file(entry):
    """é¸æ“‡å½±ç‰‡æª”æ¡ˆ"""
    path = filedialog.askopenfilename(filetypes=[("MP4 files", "*.mp4")])
    if path:
        entry.delete(0, tk.END)
        entry.insert(0, path)

def browse_slides_dir(entry):
    """é¸æ“‡ç¿»è­¯å¾ŒæŠ•å½±ç‰‡ç›®éŒ„"""
    path = filedialog.askdirectory()
    if path:
        entry.delete(0, tk.END)
        entry.insert(0, path)

def browse_output_file(entry):
    """é¸æ“‡è¼¸å‡ºå½±ç‰‡è·¯å¾‘"""
    path = filedialog.asksaveasfilename(defaultextension=".mp4", filetypes=[("MP4 files", "*.mp4")])
    if path:
        entry.delete(0, tk.END)
        entry.insert(0, path)

def start_video_process(video_entry, slides_entry, output_entry, interval_entry, threshold_entry, status_label, progress_label):
    """é–‹å§‹è™•ç†å½±ç‰‡"""
    video_path = video_entry.get()
    slides_dir = slides_entry.get()
    output_path = output_entry.get()
    
    # æª¢æŸ¥è¼¸å…¥
    if not os.path.isfile(video_path):
        messagebox.showerror("éŒ¯èª¤", "å½±ç‰‡è·¯å¾‘éŒ¯èª¤æˆ–ä¸å­˜åœ¨ï¼")
        return
    
    if not os.path.isdir(slides_dir):
        messagebox.showerror("éŒ¯èª¤", "ç¿»è­¯æŠ•å½±ç‰‡ç›®éŒ„ä¸å­˜åœ¨ï¼")
        return
    
    if not output_path:
        messagebox.showerror("éŒ¯èª¤", "è«‹æŒ‡å®šè¼¸å‡ºå½±ç‰‡è·¯å¾‘ï¼")
        return
    
    try:
        interval = int(interval_entry.get())
        threshold = int(threshold_entry.get())
    except ValueError:
        messagebox.showerror("éŒ¯èª¤", "è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—åƒæ•¸")
        return
    
    status_label.config(text="ğŸš€ æ­£åœ¨è™•ç†å½±ç‰‡...")
    progress_label.config(text="æº–å‚™ä¸­...")
    
    # åœ¨æ–°åŸ·è¡Œç·’ä¸­è™•ç†å½±ç‰‡ï¼Œä»¥å…é˜»å¡UI
    threading.Thread(target=create_translated_video, 
                     args=(video_path, slides_dir, output_path, interval, threshold, status_label, progress_label)).start()


# === å‰µå»ºåŸå§‹åŠŸèƒ½çš„æ¨™ç±¤é  ===
def create_extraction_tab(notebook):
    """å‰µå»ºæŠ•å½±ç‰‡æ“·å–èˆ‡ç¿»è­¯çš„æ¨™ç±¤é """
    tab = ttk.Frame(notebook)
    
    tk.Label(tab, text="Gemini API é‡‘é‘°ï¼š").pack()
    api_key_entry = tk.Entry(tab, width=50)
    api_key_entry.pack()
    tk.Button(tab, text="é–å®šé‡‘é‘°", command=lock_api).pack(pady=10)

    tk.Label(tab, text="ğŸï¸ é¸æ“‡å½±ç‰‡æª”æ¡ˆï¼š").pack()
    video_entry = tk.Entry(tab, width=50)
    video_entry.pack()
    tk.Button(tab, text="ç€è¦½...", command=lambda: browse_file(video_entry)).pack()

    tk.Label(tab, text="ğŸ” å¹€é–“éš” (frame_interval)ï¼š").pack()
    interval_entry = tk.Entry(tab)
    interval_entry.insert(0, "15")
    interval_entry.pack()

    tk.Label(tab, text="âš™ï¸ Hash å·®ç•°é–€æª»ï¼š").pack()
    threshold_entry = tk.Entry(tab)
    threshold_entry.insert(0, "5")
    threshold_entry.pack()

    status_label = tk.Label(tab, text="", fg="blue")
    status_label.pack(pady=10)

    counter_label = tk.Label(tab, text="", fg="green")
    counter_label.pack()

    tk.Button(tab, text="é–‹å§‹æ“·å–", 
              command=lambda: start_process(video_entry, interval_entry, threshold_entry, status_label, counter_label),
              bg="#4CAF50", fg="white", padx=10, pady=5).pack(pady=10)
    
    return tab, api_key_entry

# === å‰µå»ºå½±ç‰‡åˆæˆçš„æ¨™ç±¤é  ===
def create_video_composition_tab(notebook):
    """å‰µå»ºç¿»è­¯å½±ç‰‡åˆæˆçš„æ¨™ç±¤é """
    tab = ttk.Frame(notebook)
    
    # åŸå§‹å½±ç‰‡
    tk.Label(tab, text="ğŸï¸ é¸æ“‡åŸå§‹å½±ç‰‡ï¼š").pack(pady=(10, 0))
    video_entry = tk.Entry(tab, width=50)
    video_entry.pack()
    tk.Button(tab, text="ç€è¦½...", command=lambda: browse_video_file(video_entry)).pack()
    
    # ç¿»è­¯å¾ŒæŠ•å½±ç‰‡ç›®éŒ„
    tk.Label(tab, text="ğŸ“ ç¿»è­¯å¾ŒæŠ•å½±ç‰‡ç›®éŒ„ï¼š").pack(pady=(10, 0))
    slides_entry = tk.Entry(tab, width=50)
    slides_entry.insert(0, "ocr_output")
    slides_entry.pack()
    tk.Button(tab, text="ç€è¦½...", command=lambda: browse_slides_dir(slides_entry)).pack()
    
    # è¼¸å‡ºå½±ç‰‡è·¯å¾‘
    tk.Label(tab, text="ğŸ’¾ è¼¸å‡ºå½±ç‰‡è·¯å¾‘ï¼š").pack(pady=(10, 0))
    output_entry = tk.Entry(tab, width=50)
    output_entry.insert(0, "output_video.mp4")
    output_entry.pack()
    tk.Button(tab, text="ç€è¦½...", command=lambda: browse_output_file(output_entry)).pack()
    
    # åƒæ•¸è¨­å®š
    params_frame = tk.Frame(tab)
    params_frame.pack(pady=10)
    
    tk.Label(params_frame, text="ğŸ” å¹€é–“éš”ï¼š").grid(row=0, column=0, padx=5)
    interval_entry = tk.Entry(params_frame, width=10)
    interval_entry.insert(0, "15")
    interval_entry.grid(row=0, column=1, padx=5)
    
    tk.Label(params_frame, text="âš™ï¸ Hash å·®ç•°é–€æª»ï¼š").grid(row=0, column=2, padx=5)
    threshold_entry = tk.Entry(params_frame, width=10)
    threshold_entry.insert(0, "5")
    threshold_entry.grid(row=0, column=3, padx=5)
    
    # ç‹€æ…‹å’Œé€²åº¦æ¨™ç±¤
    status_label = tk.Label(tab, text="", fg="blue")
    status_label.pack(pady=10)
    
    progress_label = tk.Label(tab, text="", fg="green")
    progress_label.pack()
    
    # é–‹å§‹è™•ç†æŒ‰éˆ•
    tk.Button(tab, text="é–‹å§‹åˆæˆå½±ç‰‡", 
              command=lambda: start_video_process(video_entry, slides_entry, output_entry, 
                                                 interval_entry, threshold_entry,
                                                 status_label, progress_label),
              bg="#4CAF50", fg="white", padx=10, pady=5).pack(pady=20)
    
    return tab

# === ä¸»ç¨‹å¼ ===
def main():
    global api_key_entry  # ä½¿å…¶æˆç‚ºå…¨åŸŸè®Šæ•¸ï¼Œä»¥ä¾¿åœ¨ lock_api å‡½æ•¸ä¸­ä½¿ç”¨
    
    root = tk.Tk()
    root.title("æŠ•å½±ç‰‡ç¿»è­¯èˆ‡å½±ç‰‡åˆæˆå·¥å…·")
    root.geometry("600x500")
    
    # å‰µå»ºé¸é …å¡
    notebook = ttk.Notebook(root)
    notebook.pack(fill='both', expand=True, padx=10, pady=10)
    
    # æ·»åŠ åŸå§‹åŠŸèƒ½çš„æ¨™ç±¤é 
    extraction_tab, api_key_entry = create_extraction_tab(notebook)
    notebook.add(extraction_tab, text="æŠ•å½±ç‰‡æ“·å–èˆ‡ç¿»è­¯")
    
    # æ·»åŠ å½±ç‰‡åˆæˆåŠŸèƒ½çš„æ¨™ç±¤é 
    composition_tab = create_video_composition_tab(notebook)
    notebook.add(composition_tab, text="ç¿»è­¯å½±ç‰‡åˆæˆ")
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    os.makedirs("slides_output", exist_ok=True)
    os.makedirs("ocr_output", exist_ok=True)
    
    root.mainloop()

if __name__ == "__main__":
    main()