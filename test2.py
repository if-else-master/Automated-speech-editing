import cv2
import easyocr
import cv2
import numpy as np
import imagehash
from PIL import Image, ImageDraw, ImageFont
import requests 
import re
import os
import threading
import tkinter as tk
from tkinter import filedialog, messagebox

def lock_api():
    global GEMINI_API_KEY
    GEMINI_API_KEY = api_key_entry.get()
    print("ğŸ”‘ é–å®šé‡‘é‘°:", GEMINI_API_KEY)
    
GEMINI_API_KEY = ""

def extract_slides(video_path, output_dir, frame_interval, hash_diff_threshold, status_label, counter_label):
    os.makedirs(output_dir, exist_ok=True)
    cap = cv2.VideoCapture(video_path)

    frame_count = 0
    prev_hash = None
    slide_index = 0
    output_img = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        if frame_count % frame_interval == 0:
            pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            curr_hash = imagehash.phash(pil_image)

            if prev_hash is None or abs(curr_hash - prev_hash) > hash_diff_threshold:
                filename = os.path.join(output_dir, f'slide_{slide_index:02d}.jpg')
                pil_image.save(filename)
                process_image(filename,f'ocr_output/out_{output_img:02d}.jpg')
                slide_index += 1
                output_img += 1
                prev_hash = curr_hash
                counter_label.config(text=f"å·²æ“·å–é æ•¸ï¼š{slide_index}")

        frame_count += 1

    cap.release()
    status_label.config(text="ğŸ‰ æ“·å–å®Œæˆï¼")
    messagebox.showinfo("å®Œæˆ", f"æˆåŠŸæ“·å– {slide_index} å¼µæŠ•å½±ç‰‡ï¼")

def browse_file(entry):
    path = filedialog.askopenfilename(filetypes=[("MP4 files", "*.mp4")])
    entry.delete(0, tk.END)
    entry.insert(0, path)

def start_process(video_entry, interval_entry, threshold_entry, status_label, counter_label):
    video_path = video_entry.get()
    if not os.path.isfile(video_path):
        messagebox.showerror("éŒ¯èª¤", "å½±ç‰‡è·¯å¾‘éŒ¯èª¤æˆ–ä¸å­˜åœ¨ï¼")
        return

    try:
        interval = int(interval_entry.get())
        threshold = int(threshold_entry.get())
    except ValueError:
        messagebox.showerror("éŒ¯èª¤", "è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—åƒæ•¸")
        return

    status_label.config(text="ğŸš€ æ­£åœ¨æ“·å–ä¸­...")
    counter_label.config(text="")

    output_dir = "slides_output"
    threading.Thread(target=extract_slides, args=(video_path, output_dir, interval, threshold, status_label, counter_label)).start()
    
    
## OCR##############################
def translate_with_gemini(text, api_key, target_lang="Japanese"):
    """
    å°‡è¼¸å…¥çš„ç¹é«”ä¸­æ–‡ text ç¿»è­¯æˆ target_langï¼ˆé è¨­ Japaneseï¼‰ï¼Œ
    åƒ…å›å‚³ç¿»è­¯å¾Œçš„ç´”æ–‡å­—ï¼Œä¸åŒ…å«ä»»ä½•é¡å¤–å…§å®¹ã€‚
    """
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}"
    headers = {"Content-Type": "application/json"}
    prompt = f"è«‹å°‡ä»¥ä¸‹ç¹é«”ä¸­æ–‡ç¿»è­¯æˆ{target_lang}ï¼Œåªè¼¸å‡ºç¿»è­¯çµæœï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡‹æˆ–é¡å¤–æ–‡å­—ï¼š{text}"
    payload = {
        "contents": [{"parts": [{"text": prompt}]}]
    }
    r = requests.post(url, headers=headers, json=payload)
    if r.status_code == 200:
        try:
            translated = r.json()["candidates"][0]["content"]["parts"][0]["text"]
            # å»é™¤æ‰€æœ‰å¯èƒ½çš„å‰å°æ–‡å­—ï¼Œåªä¿ç•™å¯¦éš›ç¿»è­¯
            clean_result = re.sub(r'^[^a-zA-Z\u3040-\u30FF\u3400-\u4DBF\u4E00-\u9FFF]+', '', translated).strip()
            return clean_result
        except (KeyError, IndexError):
            return text
    else:
        print("âš ï¸ ç¿»è­¯å¤±æ•—:", r.text)
        return text

def remove_text_with_inpainting(img, boxes):
    """
    æ ¹æ“š OCR å›å‚³çš„ boxes å››é»åº§æ¨™ï¼Œè£½ä½œ mask ä¸¦ inpaintã€‚
    """
    mask = np.zeros(img.shape[:2], dtype=np.uint8)
    for box in boxes:
        pts = np.array(box, dtype=np.int32)
        cv2.fillPoly(mask, [pts], 255)
    return cv2.inpaint(img, mask, 3, cv2.INPAINT_TELEA)

def draw_translated_text(pil_img, boxes, texts, font_path):
    """
    åœ¨ PIL Image ä¸Šï¼Œä¾ç…§åŸæœ¬ boxes çš„ä½ç½®è²¼å›ç¿»è­¯å¾Œçš„æ–‡æœ¬ï¼Œ
    å‹•æ…‹è¨ˆç®—å­—å‹å¤§å°ã€æ›è¡Œï¼Œç¢ºä¿æ–‡å­—ç½®å…¥æ¡†å…§ã€‚
    """
    draw = ImageDraw.Draw(pil_img)
    for box, txt in zip(boxes, texts):
        xs = [p[0] for p in box]
        ys = [p[1] for p in box]
        x0, y0 = min(xs), min(ys)
        x1, y1 = max(xs), max(ys)
        box_w, box_h = x1 - x0, y1 - y0

        font_size = max(int(box_h * 0.8), 12)
        font = ImageFont.truetype(font_path, font_size)

        max_chars = max(int(box_w / (font_size * 0.6)), 1)
        lines = [txt[i:i+max_chars] for i in range(0, len(txt), max_chars)]

        y = y0
        for line in lines:
            draw.text((x0, y), line, font=font, fill=(0, 0, 0))
            y += font_size
    return pil_img

def process_image(image_path, output_path):
    # è®€å–åœ–ç‰‡
    img = cv2.imread(image_path)
    # OCR åƒ…åµæ¸¬ç¹é«”ä¸­æ–‡
    reader = easyocr.Reader(['ch_tra'], gpu=False)
    results = reader.readtext(img)

    boxes, orig_texts = [], []
    for box, text, conf in results:
        if conf > 0.4:
            boxes.append(box)
            orig_texts.append(text)

    # ç§»é™¤åŸæ–‡æ–‡å­—
    img_clean = remove_text_with_inpainting(img, boxes)

    # ç¿»è­¯æ‰€æœ‰æ–‡å­—
    translated = [translate_with_gemini(t, GEMINI_API_KEY, target_lang="Japanese") for t in orig_texts]

    # è½‰ç‚º PIL é€²è¡Œè²¼å­—
    pil_img = Image.fromarray(cv2.cvtColor(img_clean, cv2.COLOR_BGR2RGB))
    # æ—¥æ–‡å­—å‹
    font_jp = "NotoSansCJKjp-Regular.otf"

    final = draw_translated_text(pil_img, boxes, translated, font_jp)
    final.save(output_path)
    print(f"âœ… è¼¸å‡ºå®Œæˆï¼š{output_path}")




# === GUI è¨­è¨ˆ ===
root = tk.Tk()
root.title("æŠ•å½±ç‰‡æ“·å–å™¨")
root.geometry("500x400")

tk.Label(root, text="Gemini API é‡‘é‘°ï¼š").pack()
api_key_entry = tk.Entry(root, width=50)
api_key_entry.pack()
tk.Button(root, text="é–å®šé‡‘é‘°", command=lock_api).pack(pady=10)

tk.Label(root, text="ğŸï¸ é¸æ“‡å½±ç‰‡æª”æ¡ˆï¼š").pack()
video_entry = tk.Entry(root, width=50)
video_entry.pack()
tk.Button(root, text="ç€è¦½...", command=lambda: browse_file(video_entry)).pack()

tk.Label(root, text="ğŸ” å¹€é–“éš” (frame_interval)ï¼š").pack()
interval_entry = tk.Entry(root)
interval_entry.insert(0, "15")
interval_entry.pack()

tk.Label(root, text="âš™ï¸ Hash å·®ç•°é–€æª»ï¼š").pack()
threshold_entry = tk.Entry(root)
threshold_entry.insert(0, "5")
threshold_entry.pack()

status_label = tk.Label(root, text="", fg="blue")
status_label.pack(pady=10)

counter_label = tk.Label(root, text="", fg="green")
counter_label.pack()

tk.Button(root, text="é–‹å§‹æ“·å–", command=lambda: start_process(video_entry, interval_entry, threshold_entry, status_label, counter_label)).pack(pady=10)

root.mainloop()
